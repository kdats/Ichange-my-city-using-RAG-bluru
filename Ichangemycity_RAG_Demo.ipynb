{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdats/Ichange-my-city-using-RAG-bluru/blob/main/Ichangemycity_RAG_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About iChangeMyCity\n",
        "\n",
        "> iChangeMyCity is a civic tech platform in India, started by Janaagraha Centre for Citizenship and Democracy.  \n",
        "> It lets people file complaints about local issues like garbage, roads, streetlights, water supply, traffic, public places, and more, directly to city authorities.  \n",
        "> This platform is now one of India's largest collections of civic complaints, using regular people‚Äôs experiences to help cities.\n",
        "\n",
        "---\n",
        "\n",
        "## Objective\n",
        "\n",
        "- **Build** a RAG pipeline using open-source vector search and Google Gemini LLM  \n",
        "- **Allow** semantic question answering over real city complaint data  \n",
        "- **Show** how RAG can help people actually use large, messy data in a useful way\n",
        "\n",
        "---\n",
        "\n",
        "## About This Dataset\n",
        "\n",
        "Source: iChangeMyCity.com, covering public complaints from Bangalore between 2019 and 2022.  \n",
        "Columns:  \n",
        "- `category`: Type of civic issue (e.g. Garbage, Roads, Water, etc.)  \n",
        "- `location`: Name of the locality or neighborhood in Bangalore  \n",
        "- `ward_name`: The BBMP municipal ward name  \n",
        "- `complaint`: The complaint details or description in the user‚Äôs own words  \n",
        "- `status`: Status of the complaint (resolved, in progress, or pending)  \n",
        "- `date`: The date when the complaint was made  \n",
        "\n",
        "---\n",
        "\n",
        "## What Problem Are We Trying to Solve?\n",
        "\n",
        "Bangalore is a huge city, growing fast, so it gets a lot of civic complaints.  \n",
        "If you use regular dashboards, you can just see counts or some basic stats, but not real answers.\n",
        "\n",
        "People ‚Äì officials, citizens, journalists ‚Äì need to know things like:\n",
        "- Which areas get garbage complaints again and again\n",
        "- What are the three main unresolved infrastructure problems in a ward\n",
        "- How are civic issues changing in neighborhoods\n",
        "\n",
        "So here, the idea is to make an AI system that can answer real language questions about city complaints using RAG, pulling actual info from the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "- Data can help the city decide what to fix first and see which areas have the most problems\n",
        "- Residents, activists, or the media can find out what‚Äôs really happening in their area\n",
        "- This type of solution can work for any city if it has this kind of data\n",
        "\n",
        "---\n",
        "\n",
        "## What Does This Notebook Do?\n",
        "\n",
        "- Loads and cleans up the complaints data\n",
        "- Lets you search for meaning, not just keywords, in thousands of complaints\n",
        "- Uses Google Gemini LLM to answer your questions, using real complaint info\n",
        "- Shows how Retrieval-Augmented Generation (RAG) helps find real answers in city data\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This notebook shows a RAG pipeline that summarizes and analyzes complaints from Bangalore.  \n",
        "It can answer stuff like:\n",
        "- Which areas get the most garbage complaints\n",
        "- What‚Äôs the main complaint in a certain ward\n",
        "- Which localities have recurring water or road issues\n",
        "\n",
        "The point is to help city folks, researchers, or activists get more than just numbers ‚Äì you get real answers from the actual complaints.\n",
        "\n",
        "---\n",
        "\n",
        "## Why RAG (Retrieval-Augmented Generation)\n",
        "\n",
        "Regular language models sometimes make up facts (hallucinate) or can‚Äôt give answers based on your data.  \n",
        "RAG works by:\n",
        "- **Retrieval**: finds the most relevant info from your own database (not just the internet)\n",
        "- **Augmentation**: sends this context to the language model (here, Gemini) so it only answers based on what it found\n",
        "- **Generation**: writes a natural answer using that info\n",
        "\n",
        "This approach is good for accurate, transparent, and up-to-date results.\n",
        "\n",
        "---\n",
        "\n",
        "## Workflow Overview\n",
        "\n",
        "- Install libraries: pandas, sentence-transformers, chromadb, google-generativeai\n",
        "- Load and prepare complaint data\n",
        "- Embed complaint texts for semantic search\n",
        "- Store vectors in ChromaDB\n",
        "- Search for the most relevant complaints for a query\n",
        "- Send retrieved context and query to Gemini LLM\n",
        "- Print out answers you can use for analysis\n",
        "\n",
        "---\n",
        "\n",
        "## API Key and Security\n",
        "\n",
        "The Gemini API key is set from an environment variable or secret in the notebook.  \n",
        "This example uses a sample key ‚Äì always keep your real keys private.\n",
        "\n",
        "---\n",
        "\n",
        "## Example Use Cases\n",
        "\n",
        "- Find wards with the most unresolved infrastructure issues\n",
        "- Get top complaints for Dodda Nekkundi\n",
        "- Find out what issues came up most in 2021\n",
        "\n",
        "---\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "- Change the sample CSV and API key as needed\n",
        "- Try your own questions at the end to see how RAG works\n",
        "\n",
        "This is built with open-source and Google AI tools, and it can be used for any city‚Äôs complaint records if you have similar data.\n"
      ],
      "metadata": {
        "id": "nCAYebeK68Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_path = \"/content/env.txt\"\n",
        "csv_dataset_path = \"/content/icmyc-2019-2022.csv\""
      ],
      "metadata": {
        "id": "MCJNWgDy8Vv2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPDafRNk6tYC"
      },
      "source": [
        "#### pip install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3hC-BcN_VGHE"
      },
      "outputs": [],
      "source": [
        "! pip install -q pandas langchain chromadb google-generativeai langchain_community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stj54CVw6tYN"
      },
      "source": [
        "### Import all required libraries for data handling, embeddings, and RAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X4m65L-dVN5L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.llms import GooglePalm\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sso5tLca6tYP"
      },
      "source": [
        "#### üîë Set your Gemini API key and choose the Gemini model version (e.g., 'gemini-2.5-flash' or 'gemini-pro').\n",
        "#### ‚ö†Ô∏è **Keep your API key secret in production!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lfX9Vj9TVt6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c684da7b-85a4-490d-9dfc-f8d427feb890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI**************************************\n"
          ]
        }
      ],
      "source": [
        "# Read API key from env.txt and set it as an environment variable\n",
        "with open(\"env.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "      google_api_key = line.strip()\n",
        "\n",
        "# Now retrieve and configure for Gemini\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=google_api_key)\n",
        "print(google_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC-CqyoS6tYR"
      },
      "source": [
        "#### üì• Download a sample civic complaints CSV (or upload your own to Colab).\n",
        "#### Example sample CSV: https://data.opencity.in/datastore/dump/5f99b09a-64b5-45f0-ab18-4cf0a0cabf6d?bom=True&format=csv\n",
        "#### üëâ Replace this link or file path with your actual dataset as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6SRLnlvAWceh"
      },
      "outputs": [],
      "source": [
        "# use /content/icmyc-2019-2022.csv in google colab notebook\n",
        "\n",
        "df = pd.read_csv(csv_dataset_path, encoding_errors=\"ignore\")\n",
        "df.fillna('Unknown', inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTxJN3oQ6tYS"
      },
      "source": [
        "### Prepare Text Chunks for Embedding\n",
        "#### Convert complaint records into single text fields for vectorization.\n",
        "#### (Optional) Chunk large text for better semantic search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TPwiarFUW5hD"
      },
      "outputs": [],
      "source": [
        "# Prepare combined text for each record\n",
        "df['text'] = (\n",
        "    \"category_title: \" + df['category_title'].astype(str) +\n",
        "    \"; location: \" + df['location'].astype(str) +\n",
        "    \"; war_title: \" + df['ward_title'].astype(str) +\n",
        "    \"; description: \" + df['description'].astype(str) +\n",
        "    \"; complaint_status_title: \" + df['complaint_status_title'].astype(str) +\n",
        "    \"; created_at: \" + df['created_at'].astype(str)\n",
        ")\n",
        "\n",
        "# Load as LangChain documents\n",
        "loader = DataFrameLoader(df, page_content_column='text')\n",
        "documents = loader.load()\n",
        "\n",
        "# Enrich with metadata\n",
        "for doc, (_, row) in zip(documents, df.iterrows()):\n",
        "    doc.metadata = {\n",
        "        \"location\": row[\"location\"],\n",
        "        \"Category\": row[\"category_title\"],\n",
        "        \"war_title\": row[\"ward_title\"],\n",
        "        \"complaint_status_title\": row[\"complaint_status_title\"],\n",
        "        \"created_at\": row[\"created_at\"]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnBp2QCfYfVe",
        "outputId": "48973780-86d2-474b-a278-d57dec672b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 454\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=150,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \";\", \".\", \" \"]\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "print(f\"Total chunks created: {len(texts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrOVjW_Y6tYU"
      },
      "source": [
        "### Generate Embeddings with Sentence Transformers\n",
        "####  Embed all text chunks using a lightweight, high-quality open-source model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L5JrukFJZJuq"
      },
      "outputs": [],
      "source": [
        "! pip install -q sentence-transformers\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYDI-xyAbJSh"
      },
      "source": [
        "### Create a Chroma Vector Database\n",
        "####  Create a vector store in Chroma for fast similarity search and semantic retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zxCd2vtmYi96"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    texts,\n",
        "    embeddings,\n",
        "    persist_directory=\"./vectordb\"\n",
        ")\n",
        "vectordb.persist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpe2ykbX6tYV"
      },
      "source": [
        " ### Retrieval Function (Vector Search)\n",
        " #### Function to retrieve the top-K most relevant chunks for a user query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eivVRj_3bNhw"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"mmr\",      # Maximal Marginal Relevance (diverse & relevant)\n",
        "    search_kwargs={\"k\": 6, \"fetch_k\": 20}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD8L0De56tYW"
      },
      "source": [
        "### RAG QA ‚Äì Query Gemini LLM Using Retrieved Context\n",
        "#### Use Gemini LLM (via API) to answer the user's question, given the retrieved context.\n",
        "User Wrapper to go from user query ‚Üí retrieve docs ‚Üí get answer from Gemini\n",
        "<br>Run some real-world civic complaints analytics queries!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "7JE0REL-bUOn",
        "outputId": "9e83d696-82c4-4c8b-d43f-25da4b33a8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most garbage dump prone areas:\n",
            " Based on the complaints records, the following areas are prone to garbage dumping issues:\n",
            "\n",
            "*   **Marithi Nilaya #17, 1St Lane,1St Cross Nagalingeswara Temple, Kundalahalli, Brookefield**: This location has repeated complaints regarding the lack of regular garbage collection.\n",
            "*   **Near Collins Aerospace, Vijayanagar, Epip Zone, Whitefield**: A complaint was filed about a large garbage dump in this area.\n",
            "*   **SLS Square Front Gate Road, Phase 2, Brookefield**: A huge dumping zone was reported in front of this location.\n",
            "*   **ITPL Bypass Road, Doddanekkundi Extension, Friends Layout**: A complaint was made about garbage not being picked up on time.\n",
            "*   **7th H Cross Road, Dodda Nekkundi Extension, Chinnapanna Halli**: This area has issues with waste dumping in open places due to irregular collection by municipal workers.\n",
            "Areas with most infra issues:\n",
            " Based on the provided records, the following areas have multiple infrastructure-related complaints:\n",
            "\n",
            "*   Hanuma Reddy Layout, Chinnapanna Halli\n",
            "*   Aecs Layout (mentioned in both Marathahalli and Brookefield)\n",
            "Ward 85 top complaints:\n",
            " Based on the complaints records from Dodda Nekkundi, here are the top 3 common complaints in ranked order:\n",
            "\n",
            "1.  Mobility - Roads, Footpaths and Infrastructure\n",
            "2.  Garbage and Unsanitary Practices\n",
            "3.  Crime and Safety\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import warnings\n",
        "\n",
        "# (Assume you have set your API key and built the retriever)\n",
        "warnings.filterwarnings('ignore')\n",
        "def ask_gemini(context, query):\n",
        "    genai.configure(api_key=google_api_key)\n",
        "    model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "    prompt = (\n",
        "        \"You are an expert civic complaints analyst AI.\\n\"\n",
        "        \"Answer the following query using only the given context (from complaints records).\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Query: {query}\\nAnswer:\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "def get_rag_answer(query, retriever, k=8):\n",
        "    # Retrieve top-k chunks using your retriever\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    context = \"\\n\".join(doc.page_content for doc in docs)\n",
        "    return ask_gemini(context, query)\n",
        "\n",
        "# Example queries\n",
        "query1 = \"Which areas are most prone to garbage dumping issues?\"\n",
        "resp1 = get_rag_answer(query1, retriever)\n",
        "print(\"Most garbage dump prone areas:\\n\", resp1)\n",
        "\n",
        "query2 = \"List the areas that are likely to have the most infrastructure related complaints.\"\n",
        "resp2 = get_rag_answer(query2, retriever)\n",
        "print(\"Areas with most infra issues:\\n\", resp2)\n",
        "\n",
        "query3 = \"What are the most top 3 common complaints from Dodda Nekkundi in rankwise order ?\"\n",
        "resp3 = get_rag_answer(query3, retriever)\n",
        "print(\"Ward 85 top complaints:\\n\", resp3)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
